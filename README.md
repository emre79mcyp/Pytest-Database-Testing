# PyTest Database Testing Framework
SQLite + pytest fixtures for API/database integration testing with analytics pipeline validation

---

## ğŸ“Œ Project Structure

```
project/
â”‚
â”œâ”€â”€ database/
â”‚   â””â”€â”€ test_data.db              # auto-created when tests run
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py               # pytest fixtures (DB setup, cleanup)
â”‚   â”œâ”€â”€ test_api_with_database.py # API + DB integration tests
â”‚   â”œâ”€â”€ test_database_crud.py     # CRUD operations & SQL
â”‚   â””â”€â”€ test_analytics_pipeline.py # ğŸ†• Analytics & data pipeline tests
â”‚
â”œâ”€â”€ create_database.py            # Database initialization script
â”œâ”€â”€ requirements.txt              # Dependencies
â””â”€â”€ README.md                     # This file
```

---

## âš™ï¸ Fixtures Overview (conftest.py)

### ğŸ”¹ db_connection Fixture

Creates `database/test_data.db` if it doesn't exist
- Enables foreign keys
- Creates required tables:
  - `users(id, name, email)`
  - `bookings(id, user_id, pickup, dropoff, price, status DEFAULT 'confirmed')`
  - `booking_events(id, booking_id, event_type, revenue)` ğŸ†• **NEW - Analytics**
- Provides a live SQLite connection to tests
- Closes the DB after tests complete

```python
@pytest.fixture
def db_connection():
    """Create and configure database connection"""
    db_path = 'database/test_data.db'
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    
    cursor = conn.cursor()
    
    # Create tables
    cursor.execute("""CREATE TABLE users (...)""")
    cursor.execute("""CREATE TABLE bookings (...)""")
    cursor.execute("""CREATE TABLE booking_events (...)""")  # ğŸ†• Analytics
    
    conn.commit()
    yield conn
    conn.close()
```

### ğŸ”¹ clean_database Fixture

Executed before every test:
- Deletes all rows from `booking_events` ğŸ†• **NEW - Analytics**
- Deletes all rows from `bookings`
- Deletes all rows from `users`
- Ensures every test starts with a fresh database

```python
@pytest.fixture
def clean_database(db_connection):
    """Clean database before each test"""
    cursor = db_connection.cursor()
    
    cursor.execute("DELETE FROM booking_events")  # ğŸ†• Analytics
    cursor.execute("DELETE FROM bookings")
    cursor.execute("DELETE FROM users")
    
    db_connection.commit()
    yield db_connection
```

---

## ğŸ§ª Running Tests

### Prerequisites
```bash
pip install pytest
```

### Run all tests
```bash
pytest -v
```

### Run a single file
```bash
pytest tests/test_api_with_database.py -v
pytest tests/test_database_crud.py -v
pytest tests/test_analytics_pipeline.py -v        # ğŸ†• Analytics tests
```

### Run specific test
```bash
pytest tests/test_analytics_pipeline.py::test_booking_creates_analytics_event -v
```

### Run with coverage
```bash
pytest tests/ -v --cov
```

---

## ğŸ“˜ What the Tests Cover

### âœ”ï¸ API & Database Integration
- **test_simulated_api_creates_database_record**
  - Simulates API call inserting a user
  - Verifies data matches what is stored in DB

- **test_booking_price_calculation_validation**
  - Checks that pricing business logic is stored correctly

### âœ”ï¸ Data Integrity & Relationships
- **test_data_integrity_foreign_key**
  - Asserts SQLite raises `IntegrityError` when referencing non-existent user
  - Validates foreign key constraints work

- **test_booking_user_relationship**
  - Ensures JOIN queries return correct relational data
  - Validates user-booking relationships

### âœ”ï¸ CRUD Operations
- **test_create_user**
  - Validates INSERT for users table

- **test_create_booking**
  - Validates INSERT for bookings table

- **test_multiple_bookings**
  - Parametrized test: creates multiple bookings with different parameters

### âœ”ï¸ ğŸ†• ANALYTICS PIPELINE TESTS (NEW!)

Complete data pipeline validation with 7 passing tests:

#### 1. **test_booking_creates_analytics_event** âœ…
- Verifies when booking is created â†’ analytics event is created
- Tests INSERT into both bookings and booking_events tables
- Validates event data persists

```python
def test_booking_creates_analytics_event(clean_database):
    cursor = clean_database.cursor()
    
    # Insert user
    cursor.execute("INSERT INTO users (name, email) VALUES (?, ?)", ...)
    user_id = cursor.lastrowid
    
    # Insert booking
    cursor.execute("INSERT INTO bookings (...) VALUES (...)")
    booking_id = cursor.lastrowid
    
    # Insert analytics event
    cursor.execute("""
        INSERT INTO booking_events (booking_id, event_type, revenue)
        VALUES (?, ?, ?)
    """, (booking_id, "booking_created", 230.00))
    
    # Fetch and validate
    cursor.execute("SELECT * FROM booking_events WHERE booking_id = ?")
    event = cursor.fetchone()
    assert event["event_type"] == "booking_created" âœ…
```

#### 2. **test_booking_data_consistency_across_systems** âœ…
- Validates price consistency between main DB and analytics
- Inserts booking with price=150.00
- Inserts event with revenue=150.00
- SELECTS from both tables and compares

```python
def test_booking_data_consistency_across_systems(clean_database):
    # Insert booking with price
    cursor.execute("INSERT INTO bookings ... price=150.00")
    booking_id = cursor.lastrowid
    
    # Insert event with revenue
    cursor.execute("INSERT INTO booking_events ... revenue=150.00")
    
    # Fetch both and compare
    cursor.execute("SELECT price FROM bookings WHERE id = ?")
    db_price = cursor.fetchone()["price"]
    
    cursor.execute("SELECT revenue FROM booking_events WHERE booking_id = ?")
    analytics_price = cursor.fetchone()["revenue"]
    
    assert db_price == analytics_price âœ…  # 150.00 == 150.00
```

#### 3. **test_multiple_booking_events_pipeline** âœ…
- Tests complete workflow: create â†’ confirm â†’ assign
- Inserts 3 events for same booking
- Validates all events created and tracked

```python
def test_multiple_booking_events_pipeline(clean_database):
    # Insert booking
    cursor.execute("INSERT INTO bookings ... status='pending'")
    booking_id = cursor.lastrowid
    
    # EVENT 1: booking_created
    cursor.execute("INSERT INTO booking_events ... event_type='booking_created'")
    
    # Update status and EVENT 2: booking_confirmed
    cursor.execute("UPDATE bookings SET status='confirmed'")
    cursor.execute("INSERT INTO booking_events ... event_type='booking_confirmed'")
    
    # Update status and EVENT 3: driver_assigned
    cursor.execute("UPDATE bookings SET status='driver_assigned'")
    cursor.execute("INSERT INTO booking_events ... event_type='driver_assigned'")
    
    # Validate 3 events created
    cursor.execute("SELECT COUNT(*) FROM booking_events WHERE booking_id = ?")
    count = cursor.fetchone()["COUNT(*)"]
    assert count == 3 âœ…
```

#### 4-6. **test_pricing_pipeline_all_routes** (Parametrized) âœ… âœ… âœ…
- Tests pricing for 3 routes: Geneva, Zurich, Munich
- Parametrized test runs 3 times with different routes

```python
@pytest.mark.parametrize("pickup,dropoff,expected_price", [
    ("Geneva Airport", "Chamonix", 230.00),
    ("Zurich Airport", "St. Moritz", 200.00),
    ("Munich Airport", "Garmisch", 120.00),
])
def test_pricing_pipeline_all_routes(clean_database, pickup, dropoff, expected_price):
    # Insert booking with pricing
    cursor.execute("INSERT INTO bookings ... price=?", (expected_price,))
    booking_id = cursor.lastrowid
    
    # Insert analytics event
    cursor.execute("INSERT INTO booking_events ... revenue=?", (expected_price,))
    
    # Fetch and verify
    cursor.execute("SELECT price FROM bookings WHERE id = ?")
    db_price = cursor.fetchone()["price"]
    
    cursor.execute("SELECT revenue FROM booking_events WHERE booking_id = ?")
    analytics_price = cursor.fetchone()["revenue"]
    
    assert db_price == expected_price âœ…
    assert analytics_price == expected_price âœ…
```

#### 7. **test_analytics_revenue_aggregation** âœ…
- Tests SUM() queries on revenue
- Inserts 3 bookings (230 + 200 + 120 = 550)
- Validates total revenue calculated correctly

```python
def test_analytics_revenue_aggregation(clean_database):
    # Insert 3 bookings with different prices
    bookings_data = [
        ("User1", "user1@test.com", "Geneva", "Chamonix", 230.00),
        ("User2", "user2@test.com", "Zurich", "St. Moritz", 200.00),
        ("User3", "user3@test.com", "Munich", "Garmisch", 120.00),
    ]
    
    total_expected = 0
    for name, email, pickup, dropoff, price in bookings_data:
        # Insert user
        cursor.execute("INSERT INTO users ...")
        user_id = cursor.lastrowid
        
        # Insert booking
        cursor.execute("INSERT INTO bookings ...")
        booking_id = cursor.lastrowid
        total_expected += price
        
        # Insert event
        cursor.execute("INSERT INTO booking_events ... revenue=?", (price,))
    
    # Validate total using SUM()
    cursor.execute("""
        SELECT SUM(revenue) as total FROM booking_events 
        WHERE event_type = 'booking_created'
    """)
    analytics_total = cursor.fetchone()["total"]
    
    assert analytics_total == 550.00 âœ…
```

---

## ğŸ“Š Database Schema (with Analytics)

### Users Table
```sql
CREATE TABLE users (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    email TEXT NOT NULL
);
```

### Bookings Table
```sql
CREATE TABLE bookings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id INTEGER NOT NULL,
    pickup TEXT NOT NULL,
    dropoff TEXT NOT NULL,
    price DECIMAL(10,2) NOT NULL,
    status TEXT DEFAULT 'confirmed',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users (id)
);
```

### ğŸ†• Booking Events Table (Analytics)
```sql
CREATE TABLE booking_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    booking_id INTEGER NOT NULL,
    event_type TEXT NOT NULL,
    revenue DECIMAL(10,2),
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (booking_id) REFERENCES bookings(id)
);
```

---

## ğŸ”„ Data Pipeline Flow

```
User Books â†’ API Receives â†’ Booking Saved â†’ Analytics Event Created â†’ Validated
    â†“            â†“              â†“                      â†“                  â†“
Simulated   test_simulated    INSERT             INSERT into        SELECT &
API call    _api_creates      into bookings      booking_events     ASSERT
            _database_record
```

### Analytics Pipeline Steps:

1. **INSERT Data**
   ```python
   cursor.execute("INSERT INTO bookings ...")
   cursor.execute("INSERT INTO booking_events ...")
   clean_database.commit()
   ```

2. **SELECT/FETCH Data**
   ```python
   cursor.execute("SELECT revenue FROM booking_events WHERE booking_id = ?")
   result = cursor.fetchone()
   ```

3. **VALIDATE Data**
   ```python
   assert result["revenue"] == expected_price
   ```

---

## ğŸ¯ SQL Queries Used in Analytics Tests

### Simple SELECT
```python
cursor.execute("SELECT revenue FROM booking_events WHERE booking_id = ?", (1,))
result = cursor.fetchone()
print(result["revenue"])
```

### SELECT with COUNT
```python
cursor.execute("SELECT COUNT(*) FROM booking_events WHERE booking_id = ?", (1,))
count = cursor.fetchone()["COUNT(*)"]
```

### JOIN Query (Multiple Tables)
```python
cursor.execute("""
    SELECT b.price, e.revenue
    FROM bookings b
    JOIN booking_events e ON b.id = e.booking_id
    WHERE b.id = ?
""", (booking_id,))
result = cursor.fetchone()
```

### Aggregate Query (SUM)
```python
cursor.execute("""
    SELECT SUM(revenue) as total FROM booking_events
    WHERE event_type = 'booking_created'
""")
total = cursor.fetchone()["total"]
```

---

## ğŸ“ˆ Test Results Summary

### Current Test Coverage

| Category | Tests | Status |
|----------|-------|--------|
| API Integration | 1 | âœ… |
| CRUD Operations | 3-4 | âœ… |
| Data Integrity | 2 | âœ… |
| ğŸ†• Analytics Pipeline | 7 | âœ… |
| **TOTAL** | **13-14** | **âœ… ALL PASSING** |

### Analytics Tests Specifically
```
âœ… test_booking_creates_analytics_event
âœ… test_booking_data_consistency_across_systems
âœ… test_multiple_booking_events_pipeline
âœ… test_pricing_pipeline_all_routes[Geneva...]
âœ… test_pricing_pipeline_all_routes[Zurich...]
âœ… test_pricing_pipeline_all_routes[Munich...]
âœ… test_analytics_revenue_aggregation

Execution: 0.29 seconds | Success Rate: 100%
```

---

## ğŸ”§ How to Add More Analytics Tests

1. Create test function in `test_analytics_pipeline.py`
2. Use `clean_database` fixture for clean state
3. Follow pattern:
   - INSERT data
   - SELECT/FETCH data
   - ASSERT validation

```python
def test_new_analytics_feature(clean_database):
    """Test new analytics feature"""
    cursor = clean_database.cursor()
    
    # INSERT
    cursor.execute("INSERT INTO booking_events ...")
    clean_database.commit()
    
    # FETCH
    cursor.execute("SELECT ... FROM booking_events ...")
    result = cursor.fetchone()
    
    # VALIDATE
    assert result["column"] == expected_value âœ…
```

---

## ğŸ’¡ Key Concepts

### Fixtures Lifecycle
```python
@pytest.fixture
def db_connection():
    # SETUP - runs before test
    conn = sqlite3.connect(...)
    
    yield conn  # TEST RUNS HERE
    
    # TEARDOWN - runs after test
    conn.close()
```

### Parametrization
```python
@pytest.mark.parametrize("param1,param2,expected", [
    (value1, value2, result1),
    (value3, value4, result2),
])
def test_something(param1, param2, expected):
    # Test runs multiple times with different values
```

### Accessing Row Data
```python
cursor.execute("SELECT name, email FROM users WHERE id = 1")
row = cursor.fetchone()

# Access by column name
print(row["name"])
print(row["email"])
```

---

## ğŸš€ Summary

This project provides:

âœ… **Clean test isolation** - Each test runs with fresh database
âœ… **Fixtures for setup/teardown** - conftest.py manages DB lifecycle
âœ… **API + Database testing** - Validates end-to-end operations
âœ… **Foreign key validation** - Ensures data integrity
âœ… **Analytics pipeline testing** - NEW! Validates complete data flow
âœ… **Parametrized tests** - Tests multiple scenarios efficiently
âœ… **SQL query examples** - JOINs, aggregates, parametrized queries
âœ… **Production-ready patterns** - Professional test structure

---

## ğŸ“š Next Steps

1. âœ… Run tests: `pytest tests/ -v`
2. âœ… Check analytics tests: `pytest tests/test_analytics_pipeline.py -v`
3. âœ… Add more analytics features as needed
4. âœ… Use as template for other testing scenarios

---

**Status:** Production Ready âœ…
**Last Updated:** December 2024
